# AI模型配置
HF_ENDPOINT=https://hf-mirror.com
# 剧本分镜智能体配置示例
# 请复制此文件为.env并填入实际的API密钥

######################### AI 模型配置############################### 
# 默认使用的AI提供商，可选值：openai, qwen, deepseek, ollama
AI_PROVIDER=openai

# 生成温度参数，控制输出的随机性 0.0 = 确定性输出，1.0 = 最大随机性
AI_TEMPERATURE=0.7

# 默认API超时时间（秒）
AI_API_TIMEOUT=60
# 最大重试次数
AI_RETRY_COUNT=3

# 最大生成令牌数
AI_MAX_TOKENS=2000

######################### LLM API 配置############################### 
#============== OpenAI API 配置
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o
# 备用模型，当默认模型不可用时使用
# OPENAI_FALLBACK_MODEL=gpt-3.5-turbo

#============== 文心一言配置
QWEN_API_KEY=your_qwen_api_key_here
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_MODEL=qwen-plus
# 备用模型，当默认模型不可用时使用
# QWEN_FALLBACK_MODEL=qwen3.5
# Linux / macOS
# export DASHSCOPE_API_KEY= $env:QWEN_API_KEY
# Windows (PowerShell)
# $env:DASHSCOPE_API_KEY = $env:QWEN_API_KEY

#============== DeepSeek配置
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-plus
# 备用模型，当默认模型不可用时使用
# DEEPSEEK_FALLBACK_MODEL=deepseek-3.5

#============== Ollama配置（不需要key）
OLLAMA_API_KEY=your_ollama_api_key_here
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=ollama-plus
# 备用模型，当默认模型不可用时使用
# OLLAMA_FALLBACK_MODEL=qwen3


# 注意事项：
# 1. 请确保设置有效的OpenAI API密钥
# 2. 对于中文剧本，推荐使用支持中文的模型
# 3. 调试模式会记录详细日志，可能会包含敏感信息


########################## 应用配置 ############################## 

#######  服务器端口，支持PORT或API_PORT环境变量
PORT=8000
#######  服务器主机，支持HOST或API_HOST环境变量
# HOST=0.0.0.0
#######  工作进程数，支持WORKERS或API_WORKERS环境变量
# WORKERS=1


#######  应用配置 调试模式，设置为True可启用详细日志
APP_DEBUG=False

####### 开发模式 - 设置为true可以在没有API密钥的情况下运行基本功能
# DEV_MODE=false

